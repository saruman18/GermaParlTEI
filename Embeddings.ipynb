{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saruman18/GermaParlTEI/blob/main/Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yusd1DaFBKZP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yQXHzBNimyuE",
        "outputId": "b66ad5d7-cdac-4a23-8fc0-06d9568d0581"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-66f135623d35>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import torch as torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoModel, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0A6AMrCTxq89"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJMkA0b1nto3"
      },
      "outputs": [],
      "source": [
        "df = pd.read_pickle(\"BT16.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqDm17Uexq8-"
      },
      "outputs": [],
      "source": [
        "# handle CSU\n",
        "df['Party'] = df['Party'].replace(['CDU','CSU'],'CDU/CSU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fCdcWL0xq8_"
      },
      "outputs": [],
      "source": [
        "#select the year\n",
        "df = df[df['year']==2006]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Y_jYpSRxq9A",
        "outputId": "1d0832ed-3da9-40df-91e4-70612caf203e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Party\n",
              "SPD          2000\n",
              "FDP          2000\n",
              "CDU/CSU      2000\n",
              "DIE LINKE    2000\n",
              "GRUENE       2000\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#draw stratified random samples\n",
        "\n",
        "strata = df['Party'].unique()\n",
        "num_strata = len(strata)\n",
        "\n",
        "total_sample = 10000\n",
        "per_stratum = total_sample // num_strata\n",
        "\n",
        "sampled_data= []\n",
        "\n",
        "for stratum in strata:\n",
        "    stratum_data=df[df['Party']==stratum]\n",
        "    sample_size = per_stratum\n",
        "    sampled_stratum = stratum_data.sample(sample_size, random_state=32)\n",
        "    sampled_data.append(sampled_stratum)\n",
        "\n",
        "df = pd.concat(sampled_data)\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "df.Party.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BySIZPTnxq9B"
      },
      "outputs": [],
      "source": [
        "#df= df.sample(n=10000, random_state=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEpOnQcWoqmK",
        "outputId": "b7c89c03-4dc7-49e5-f3ae-1c3dd93d805c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Number', 'What', 'Description', 'Speaker', 'SpeakerNumber',\n",
            "       'SpeechText', 'Party', 'Role', 'ParliamentaryGroup', 'SessionNo',\n",
            "       'LegislativePeriod', 'Interjections', 'Date', 'year', 'month',\n",
            "       'tokens'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "eYuiPnlFpCn4",
        "outputId": "ac1366b5-0107-4762-dbab-3212cf33b6d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0            Das anhand erreichten 0,35 Prozent belegen .\n",
              "1       Als vorhin Stärkung Landwirtschaft geredet , m...\n",
              "2       Auf Seite Darstellungen scheinen immer mehr he...\n",
              "3       Wir , , , Grünen entnehme jedenfalls wortgleic...\n",
              "4       Sie Gelegenheit , Erfahrungen profitieren , vi...\n",
              "                              ...                        \n",
              "9995    Ich inhaltliche Anmerkung Sache , Kollege Aman...\n",
              "9996    Es offenkundig : Wir brauchen mehr qualitativ ...\n",
              "9997    Ich danke natürlich Kolleginnen Kollegen , daf...\n",
              "9998    Aber bleibt wahr : Jede staatliche Regelung Sc...\n",
              "9999    Wir daher Individualbesteuerung , Frauen Gehal...\n",
              "Name: tokens, Length: 10000, dtype: object"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['tokens']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlpqXfMwKcfX"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "DoI6hHBJnBpg",
        "outputId": "0a75c117-9f9d-44cb-dd41-9bc6b543f133"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-00e69fcdf4e8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mPoliticalPartyDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
          ]
        }
      ],
      "source": [
        "class PoliticalPartyDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_length):\n",
        "        self.dataframe = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "        # Create a dictionary to map party names to unique integer labels\n",
        "        self.party_to_label = {party: label for label, party in enumerate(dataframe['Party'].unique())}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.dataframe.iloc[index]\n",
        "\n",
        "        text = str(row['tokens'])\n",
        "        label = self.party_to_label[row['Party']]\n",
        "\n",
        "        inputs = self.tokenizer(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = inputs['input_ids'].squeeze()\n",
        "        attention_mask = inputs['attention_mask'].squeeze()\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "MpyRY4eL3RIe",
        "outputId": "577262a4-de4b-4ba3-83b5-fcb14a0364f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000\n"
          ]
        }
      ],
      "source": [
        "# Load the German Bert tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-german-cased\")\n",
        "\n",
        "dataframe = df\n",
        "\n",
        "max_length = 512\n",
        "\n",
        "# Instantiate the dataset\n",
        "dataset = PoliticalPartyDataset(dataframe, tokenizer, max_length)\n",
        "print(len(dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEprHK9fKU_6"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzOKzhuy3Wi1"
      },
      "outputs": [],
      "source": [
        "# Create the data loader\n",
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71VuVE16BKZU"
      },
      "source": [
        "# Get the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2x2YEy2oBKZU"
      },
      "outputs": [],
      "source": [
        "bert_model = AutoModel.from_pretrained(\"dbmdz/bert-base-german-cased\").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uAafL6LBKZV",
        "outputId": "d2c767ae-a25d-4606-c706-51a463b6d007"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEuaKOvuxq9K"
      },
      "outputs": [],
      "source": [
        "def get_embeddings(bert_model, dataloader):\n",
        "\n",
        "    bert_model.eval()\n",
        "\n",
        "    embeddings_list = []  #\n",
        "    labels_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Processing batches\", leave=False):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].tolist()\n",
        "\n",
        "            outputs = bert_model(input_ids, attention_mask)\n",
        "            embeddings = outputs.last_hidden_state\n",
        "            embeddings_list.append(embeddings)\n",
        "            labels_list.extend(labels)\n",
        "    embeddings_concatenated = torch.cat(embeddings_list, dim=0)\n",
        "\n",
        "    return {'embeddings': embeddings_concatenated, 'labels': labels_list}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1Pp6hqyxq9K",
        "outputId": "3574c388-b16a-427a-a083-434070c98e6b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                     \r"
          ]
        }
      ],
      "source": [
        "result = get_embeddings(bert_model, dataloader=data_loader)\n",
        "\n",
        "file_path = \"sample_2006_10000.pth\"\n",
        "torch.save(result, file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuzZirZUxq9K"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}